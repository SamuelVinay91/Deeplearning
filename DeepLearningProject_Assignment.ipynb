{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "DeepLearningProject_Assignment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelVinay91/Deeplearning/blob/master/DeepLearningProject_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Y_O4pmo1-e",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Project: Pet Classifier using CNN\n",
        "\n",
        "Prepration\n",
        "- Extract the ipynb file and the data in the same folder\n",
        "\n",
        "Data Set\n",
        "- A production grade program as 10,000 training images\n",
        "- This is a small program with 20 images of cats and 20 images of dogs. \n",
        "- The evaluation set has 10 images of cats and 10 images of dogs\n",
        "\n",
        "Runs\n",
        "- The student is expected to run the 100-300 training step\n",
        "- A production grade code would have about 20k-50k training steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4P0c0Mvo1-h",
        "colab_type": "text"
      },
      "source": [
        "### Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwnUmt6Eo1-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_FV1pYQo1-l",
        "colab_type": "text"
      },
      "source": [
        "### Set hyper parameters\n",
        "- Run the program with three num_steps : 100,200,300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFX4zO9qo1-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "img_size = 32\n",
        "num_channels = 3\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "img_shape = (img_size, img_size)\n",
        "trainpath='/content/drive/My Drive/Colab Notebooks/TensorFlow Project- Simplilearn/data/train'\n",
        "testpath='/content/drive/My Drive/Colab Notebooks/TensorFlow Project- Simplilearn/data/test'\n",
        "labels = {'cats': 0, 'dogs': 1}\n",
        "fc_size=32 #size of the output of final FC layer\n",
        "num_steps=300 #Try 100, 200, 300. number of steps that training data should be looped. Usually 20K\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glPLRBg1o1-o",
        "colab_type": "text"
      },
      "source": [
        "### Read the image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU8m1060o1-p",
        "colab_type": "code",
        "outputId": "e31794c7-f340-4ded-d702-548995c557f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "def read_images_classes(basepath,imgSize=img_size):\n",
        "    image_stack = []\n",
        "    label_stack = []\n",
        "\n",
        "    for counter, l in enumerate(labels):\n",
        "        path = os.path.join(basepath, l,'*g')\n",
        "        for img in glob.glob(path):\n",
        "            one_hot_vector =np.zeros(len(labels),dtype=np.int16)\n",
        "            one_hot_vector[counter]=1\n",
        "            image = cv2.imread(img)\n",
        "            im_resize = cv2.resize(image,img_shape, interpolation=cv2.INTER_CUBIC)\n",
        "            image_stack.append(im_resize)\n",
        "            label_stack.append(labels[l])            \n",
        "    return np.array(image_stack), np.array(label_stack)\n",
        "\n",
        "X_train, y_train=read_images_classes(trainpath)\n",
        "X_test, y_test=read_images_classes(testpath)\n",
        "\n",
        "#test a sample image\n",
        "print('length of train image set',len(X_train))\n",
        "print('X_data shape:', X_train.shape)\n",
        "print('y_data shape:', y_train.shape)\n",
        "\n",
        "fig1 = plt.figure() \n",
        "ax1 = fig1.add_subplot(2,2,1) \n",
        "img = cv2.resize(X_train[0],(64,64), interpolation=cv2.INTER_CUBIC)\n",
        "ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(y_train[0])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of train image set 1435\n",
            "X_data shape: (1435, 32, 32, 3)\n",
            "y_data shape: (1435,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIQAAACSCAYAAACEy2IhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deZBl133XP+fce9/e+/T0zPSMNFpm\nNLIWS5a8Jjhx7FAmpIhTSbkcqFSAUKGApJICijj5iz8DBQH/QUEZEipQASckdnCIyVIGAU7FimRZ\nsizJkkbSjGafnt5ev/Uu5/DHWe65PT3TLUvqUez3m5p6r++7y7n3nvNbv7/fT2itmdCEHMlbPYAJ\nvbNoMiEmVKHJhJhQhSYTYkIVmkyICVVoMiEmVKHJhJhQhSYTYo8khJgXQnxBCNEXQpwVQvz1Wz2m\nt4PiWz2Av0D0b4AUWAIeAv5ACPGM1vq5Wzust5bExFO5Owkh2sA6cL/W+iW77T8DF7TWn76lg3uL\naSIy9kYngdxNBkvPAPfdovG8bTSZEHujDtDdtm0TmLoFY3lbaTIh9kY9YHrbtmlg6xaM5W2lyYTY\nG70ExEKIE8G2dwPfUQolTJTKPZMQ4nOABv4Oxsr4EvCh7zQrY8Ih9k5/H2gCV4H/Cvy977TJABMO\nMaFtNOEQE6rQZEJMqEJvakIIIT4uhHhRCHFaCPEd5bH7bqVvW4cQQkQYc+wHgfPAE8BPaK2ff+uG\nN6H9pjfDId4HnNZav6q1ToHPAT/y1gxrQreK3ky0cxk4F/x9Hnj/TS8mpU6iCIRAIABQWlNo5b9L\nYeaojCRSRgBEcYSUZnsSx35bktTKbcKcL89z4sgc12w2qdfrZv8oQth9QvL8UWsctxRCVPZVSvlP\n970ocnu9wm8DTclwNdh7FEIQ2TFFkbmPOE5IksSeq2A4HAKQZZm/thD470prVOGuY0hKSToeA9Dr\n99wjYGpqmnqjYUahlL8vrbW/31dfefWa1npx+/N428PfQoifAX4GIJaS4wsHkDIikebSwzxnbdQH\nYKwLmol5gZ2pKZptEyqYmZuj3W4BsHhgAYC5+VmOLB8x2xYXiez5VlfXmJ+bA+C+d53i5EnjXOx0\npqnVapWxacrJWBQFKisA86Drdl+lNaPRCIBer8d4bF7c+vq6/+z1embfYMIopfwkSJKEqSlzL1NT\nxgO+tHSYpaWDAGx2uzz73DcBuHThAvUktsfFyMh8T7OMQb/vxwTQarU4+9qrAPzZn36FODHX+76P\n/AAnT91jnul4TDpOAbNYisLc44//2KfO7vS+3syEuAAcC/4+ardVSGv9WeCzAI1aTWsp7MJxs7ac\nwWgB0kxzKSVxbFeVlAi7i1LmiyoUeWZW6Xg0JorMjeZZXr4UrWAXHclxKoHwXEaI8rtW2p+vMlZK\nbhLca7Cv9r9FUeS5nb9VrTx7EgKkKO9b2okkZckZhT1neJIqJ9OVWxWW00YyJo7LMe1Gb2ZCPAGc\nEELcgZkInwJ2RxFFEg0obV6g0gWO42ohwD4AmUQkdqU4EQBQ5PbF5zlju3L7/R5RZNjvOB37fVSh\n/GramQQieLHSsvOKaAleclEUwQvnun2VUn4Fhr8lSUxsRZ17KUVR4Bi4FJLYTpgkLveN4thPCCml\nP1ZVJoT04yknDEhhzhfHVCZ6OL6d6NueEFrrXAjxs8AfARHw69+JrtzvNnpTOoTW+kuYIM+eKdea\nSEBkRYOIBNJ+j6SsyF0n85Mk8SvFKXPpaMxoaDhEvdHA6meWK5Ry/GZsUmC5Ek5MuB8CMYCuKmXb\nThey7VBkCCGC46yIAL9Ci6IcmxGPlhvGSckhAkVYCFGKD3tcHMWlWI1kqZDL8ruWmkhbDhtwnBvR\nvmIqtdZkRQYyAmshRLEgSjLzO8KLh1iGrDPyst49xHGakmXmOCkFSc3MiHScVV6QexGBPVEhQSge\n3Ieu/F6+FFl5QeGn+x5e2738NE29RVGruReiK8eVVkjkxUBlnEL457GTKIrjBOH1rwg3u1Wh0cqJ\nGEkUXW9phTRxXU+oQvvKIRSaNM8hkdQc+5MRNZXYwQhq3uRKqFku0qjXPauL7KcqCvLciA8pImp2\nBY4Cn4UQwlgueyTvh7jBdq2r4sN9htxiJ/9FlmWkaWb3MZygKIqK38NZIXEceW4hxDbLYJsfJfxN\nShmIA+GvnecZWWbMzkLlaFX1ZWyn/YXha8iVRmpNZjdFkSS2L15IQewti1Ku1ms1/8LdM0nT1Jui\nUgg/UaJAJxFSgigf0m7k9wjegUZ7U9dYGdaCCfwNjsKXEr6sUHyEn+U+5USSMpwQmqIoTcbCLgB3\nXJplflFcfz2zPctTBkPr5xmNvJi9EU1ExoQqtK8cQkhBrdEgjiK0XcVaUipGUeS15iSJqNfM9kat\nRmK/OzVfFbl3Axvb3XCQKIq8P0EGSuBeyPsWrv/F/q6uW+lqm2s4vF6o0ZdWhnN55351Gy4TKr+l\nP6Eylm3iKnS3K1V47qlRXjFWqsrVnIJ5I9rXCRHJiOmpKWOeuZtT2t+0RBDZu4ojSWInRxwJ0FVv\nm4yEd9UmSeInkpRVS0DcRFRU5D+ifODbDilfsig9pfYhb/dOhseUYiCcmOXx4aTy51MFzndkLBz7\nbEKz054pSWpevChdgH/Z2otNKaXXxWpxbVfP7URkTKhC+6tUWntbKYWyrJMgwhlHEYnzQ0SR5xBR\nJMvVK0sb3Dmu4jgmsSKjXq97mx8hvJMqpB1ZvNYUzqkEXhuvWhalyHDboijyIq8oylVfcTVXgl7O\n9Z75oFnlvGi0cixCVnwS5T74c6ngXrQOYi6BSz6y45OIXUXo/pqdSjEcDiuDigLNXEaRD+yYgND1\nsQXPCoX0NyoCD2ej0fAhb0H5ECuWg3s5lCxSg9fiRXX3wISrvnCAZrPhz5emaUUMhHGI7feS57mf\nEGZ/Z/KWYk4E+yutvc6R22uMRmNybzUIY1XZa6swZmFvJi/yilW0E01ExoQqtP+u6yxDBivaOGXs\nqo9Kf0K4qqQsHUw+IhlFXjREUhJZ8dKo170ShShXd+iOLgJxoKJyVYUiI/QzuJUphMEgAKytrQLw\nwre+xdaWyeg7uLhIp9Pxx4Wr0Z3D0Wg0ot/v2fPK8ndRHau3cIqCLDVgmJHFN8Rx7IE1RZEjbcS3\nUKriv3BiMy+KKufYgSYcYkIV2v+CIUJglkFpynnbyv5kvpb2uIlEOnOz1DdcIEwG3kkDKhHlOfT1\nJmG4+qWKrvtd66re4FZvHCfMzBjE03PPmUj/57/we55b/OgnPsHD7343AMPR0EPeBGXk051rNBox\nGJjVHUVxRVl1j0aiEdquWVVQ5EZfSFNz3GgYM7IIriwd+8CVVmXEtwg51dsMkPn2yWhL5qsQPkon\ntvkQypdcasc+KhiEcrUulSitlFfyiqKgcBp7KDIsgKZQBTKO/DlEMHn8+VDeilhfW+P86wZ59n8f\n+z8A/OlXvuLH0ev1iZ2LfTQKxFWO1FVmnGW5d1JBOVGyPPfWQiwFcWxnh1Le+nDKb5aOySymUhWF\ndzqpQpVAotC9rVRVW96BJiJjQhW6dTWmXGRKCB+AkkIibNRPyBIXELqASxO13JbnOWlqFC2lSvMs\ny7IdIWMeEqdKiJ1AI3AmqkIpG0mVEa12E4DLly/xB7//+wD8zy8ZXFCeZpy45ySAUSj19Wai1jow\np2P/2bDIaCmF5wrpeFxiOKIIFfghHCzO+W2MhHUcNUJQBtYch8uz3HMUe3PXPY+Q9jeWIba7cbdr\n1MLfbOjwiePYu2s9aCZJSj9EgBUcjzNvfeR5XokoOsqL0p6vKYdaEv6liTii3rC+DCHJczOmzc0N\nnn3mGQBefMWgnWMpme4YvaLIFf3BAIAszfxLUbqMmGo7YS5fvszr54z4SeLYWydJkpBb9HdBiOEM\n/Af2lopcoaxoQOEno1blhFCBs2xXecFEZExoG+2zyCihYm7Bal1CvHSwPcQZJkniNeQQMlbzsLSa\nh7FnWcrYKVpKVZJeHLMogtXjNsooIa63/PmigFVrnPiQzM3NAzDXNit6nJUu6G53k571SSB06TPR\nGhfCcxzr9OnTPP74VwGTUPSxj30MgFOn7mE4tGJMKbQoXdNOvDkfg5S553ah+NsOnPHezm2+kZ1o\n30WGiwJWcxacO7p01YbRvSiK/At3YiIK8hfipE5uH9JWr+8fWBUMcn3cM4oimk2jH3S3urz04rcA\n6G91OWgTgmZmZ4hrRnxoNMKads46kUrR7ZpJ8NJLL3tdJo4jpjptAKamprzI2Nw0tcue/NqTPPbY\nYwAcPbrMBz/0AQBaraZPBiryDK2c4yxH+9SFHdICgli5AfXYZxAk50gpKikNO9FEZEyoQrtyCCHE\nMeA/YSq4auCzWuvPCCHmgd8CjgNngE9qrddvdi6XTBIiiJMkrrirS5DHNtYXBL3MuRQu1VFHNbLc\nrMz+YOT9EFUOUa4glx+a1Ouea3Q3NvjyH/4PAJ5/5uscXV4G4IGHHuK+h98DGMxB17qbtwYGlhbH\nNbpbZtsL33qRs6+/bi+nfKreHXfc6ZW80y+fNtd44Tkym3nW7jRpthr2fFHpR8kzHIIelbMTgtxz\n1EiWDrlQyR6N/HHtZvO6dMbttBeRkQP/SGv9lBBiCviaEOJPgL8JfFlr/Su2NsSngV+82YmcyAjz\nBkwuRomH3CkPIQq8kk5kaPAh9P5Wl/W1NQAuvP4qc7MzZuAnT9BsGr2gXm94M/D1c+cB2NzcZHHR\niIYXvvk0Lz5v8itf/tbzrF25BECzWee2O+/yN+DluNNpgIG1LPqDfukFLXJWVlYA6G71/MR7/cwZ\nc3yeceedtwHw8MMPMzc7a8Zc5BULQanSlLw+xySw1gKQjSpKp5f5vB4kfCPaVWRorS9prZ+y37eA\nFzCZ3z8C/Ibd7TeAT+x2rgm98+kNKZVCiOPAw8DjwJLW+pL96TJGpOx2BuNTCIArhVJEcYkVCGFn\noR9CRiW3AJBxgiqMSNi8eoGLr58B4Nwrz6Nvu8PsKyVzswv+6g4K/8yzpqbJU1/7c+qxdeCMB7St\nL+DBhx5B2HO3Wx3i2AJxohqtltmn2TDKqMoLtHVixbUa0rJkrQqvYL5+9qy3iJy4uufE/Tz44AMA\nvPvhh5i1HGLQ75cxECHRlpMqFwOyz9FRFW5vrKs8y7z1lFhAEtzYURfSnieEEKID/C7wC1rr7ras\nZy2E2JEXheUAdkp6DSNaUkRELj8hiquOqWCiuG0uFFAoRWx/n+l0yK2W/tyzT1O3L+6uu+/k4sUr\nADz99a8D8MTjX2XUvwbA4sIsp07dD8ChxSU2rpl9syxjY30DgPW1DZ9a7yyImamOF+nd/pCBTS9E\nCG/+bvV61Oy9dFpmPLMzM5w6aVL2T9x9gtTezHg8rgBhc6dPaFU+px1wolLiJ0Ge5z6WEQVWRZZl\nbw1ARgiRYCbDb2qtP283XxFCHLa/H8bUb7yOtNaf1Vo/qrV+1LltJ/TOpb1YGQL4NeAFrfWvBj99\nEfgp4Ffs53/f/Vxmxl7nOHGqtIiCaGYVdiYD/wQAWlOrG8283upQbxn38cGlI5w98woA/+vLf8Rj\n/+8xAN71rgdp2n2uXDKSrhZJBoVbVeUK1FoztpxgfX2DixdM2YsLV1e5ds1wlGbTXPuBB055rvaN\n515mo9uz4yvT/WtJ4ssObHWNH2Jl5RprtujIYNBHJA4OKLxEUFp7uFxRFCU0oBLbMRtrtZp32Ydl\nCaQslfOwYMiNaC9L9nuAnwSeFUI8bbf9MmYi/LYQ4qeBs8An93CuCb3DadcJobX+CjfOg/voG7uc\n8GjksLhF6XIVPtoZx0kFZhcW7QCQUUzkXNfNNm1bfmh+Zob1VWPuba6tcOa8KYN17vx5Fg8cBqBj\nTdFEmiQggEa9Efg4SgRzv9/j0uXLAFy8vMKmXeFpVrqMhQxANs5XoJUrhkMUxWWhEJ3a4zOvY4zH\nKQ72gNI+YKWyHPfoi2Lnaji+9lZSL01yXeIrTCR150SineiWCfWyGooCUVaTwdeNiDxOUgCpRQu5\nyRMlNXzSS1GywnzYp2kVt/tOnfK1qTaGKd0tw6Jj6wKeajaYswioudk5YotJ1Fp5YIoSyscqBsOx\nj1aur28C8NTTzxFb3WirN/CpAzIoP6Q0SFsDq9k2ymiz0yayqQNovGWh85zCJueqLPchb1QQ89Gl\nFeLUQCFihChfp8/tzFRFIfcpCjegiet6QhXa5+CW8UOE6W9uOxiFykUFlQ4TapTnlirc5swzrUhT\ns4o3NjYczIU7jt/hz/3kN59jc8uYj9PWFG0252jUzQqcabeILceJhGDaco600Iyt/2Kr2/O+hb7F\nQ6YXr/hVF0dxWfBElLkWaYEvEzg7Y0Tb4uJBEhs0G6UpkUvlKwoyez1dFAjrfwnhED4psJJEhH8e\nIQ4UtueYvqMAMqKiCYfbwaCT3I0XWeF9/UrrAFBb+jEc64ykILdyd22zS2Zf1qGFaepWXxj2h/S3\njItZREZvaLY71KU5LhEaYeMhtVadTueAOS7XrPfMCxqORh4K7/SDdqtFzb7Y0E0sojrCTViV0bIT\n4vDBQwAsHVwisfrLOM2RVuQJVfhSiQgovKoV5HbKUq9wL74oMhDOAZX651uv171u9Jb5ISb03UP7\nrlSG6W2eRPibA3PowGMniB38Po78Np8JTpkzORyOff1KESXMzBiX8PLhwyweMPvce+puAJYWF+l1\njaJZ5Bm5g7mPhhRW8PRTxVbPcIXBcOhXWBhZDDEcPu9SizIZO4ThW2Xv2rVVBiNz3o2tLkcOGwto\nutNi7KK0SqH88wiwDzugyjXKK7xhjmmel4VJjB/iHQSQgSCTqlJOpzSF3LcwcysK4fluIskyVd7g\nkcwfcRyj89IRMzttdIH3vPtBb3GcOGmil1pGvHTajGd9dZ3YyfzuJr0rRrxsjQsyDLvPi6JMnLXj\nGI3G/uEnSeliN+zZ3SP0h+Z8Z8+Z8PjFK5e9yHvXvfd6V/jC3CwDi7rKstSnK+gAtBvmjzoRtT3T\nzeeB5nng4Nu9XsZEZEyoQvvMIa4v2gWUlWx1mXEkBD7FP0kSz4qFV6zKUoVKaR8Im52ZpqvN6ljf\nWKeZmP0XFxc5dszUxr7jTlOReZTmbHTNyh32B95SGQ16jDKLk+yP6A6NWFlbXffZ1s5drVSB4/Ch\n+AhZtZTS52BubRnH1jgd+wIfRV74Wthb3S6jvhlTq9lgcdEot416vZI+4J+hS/PS1WhoKTLywHmV\nVIJdO9Etc0ztVK2tKApU5GojaF8hplZLvBWhA3ldTgjlyyAvLMyT2WLq58+eo7Ah4aWlwywcNAim\ntLCp/I0mRxaMSBlea3DxonE2jcc501b3SFWXcxfPAHD50qVSP7FiLhZxZRKE6YcuAFyEafg+LB2j\nRImz/OpXHwfglVdeod0y4uPEHXd4kTfdbjEKKtmUz9BhLoW3arZXsqlWU5tYGRN6A3SLOESpEArw\nipOU0lcRlDKs7pqgqa6OSEZVSL4tEtJotNjaNHC6QimysWH9NVEwtq7rl2wrgkajTmJX+nSnxbpL\nzpExC4umlYSOE9oXTXQ0iQRCu0fmVlpYE7LkEGHFWFOYbHvRdOnd4/3+gG7XcKeLFy95qH+e5d7v\ncfy2o94l7wqsZXlZUKwocl8Ds1IITQVRXKV24Q+3IC+jtAcMhbUiTPGwxG4vy/OaoFhVu4+jmLoL\nfzcbCOd8yQuaFtU0N7eAbJnzHVvokHcNZOOJPzdA14yIE/e8C4DZuXnmFoyYUAja0+Z7ISNuv+12\ne27F2oaxANbWbZArzSpewdLE214Vv8wPcfu5ySGlQOOy0CRDC7J57cxZLl8xgbWV1Ws8dL8Z66FD\nBpyWZhmZNZULlSG9pNB+5ilVIJWdEESlR+0GNBEZE6rQvleQUYU2CTl2KgpRgl6iKApC0JQxhF7P\nK3O5xToWReGr3tabDZTVtgeDEb0tw35llHjU9bi/RW/DiJJ+18Q04s4siY1rzBw4QLPTsoOS1JtG\n6yeuMT9n9u+0r7Jp3d9O069W3A9hhSU3MJ/VoudVf0BZ2hiEL0V89dqQ3CrFaM0ha3FMW0XTPBN3\nbe0TlNMsI83KeIjfo1ATP8SE3hjtu1JZFAWmdoYzGQWFKFebm7+FUr4fhsoLerbf1OamUQz7/S2y\nwgaj6nXPTbobW77G1NKhg6jInPuF8xdp2tYEJ++7D4Cjd5/k8FGjH9TbU2xYxS7PFO2GMf16vb6P\ncHa7XZ+25+S8rLREKLnC9ix3R67EgTFLsceJHYu7RFpTWN0pywtWN4zesmpBv3VbFRgMd3U+nPF4\n7ME3cRQhcGl9o7Ic5A1of0UG2IYkgTNKgYjLZJTMPvyt7gYiKMm7sWGRz+umfM9g2CO1rFXGkcVE\nwqg/4qCNKB69/Tampm0RsDSl2TZWxNJtxnW9tHw7tab5vcgVBBFHZ0XUGw3mF2yC79w8V65t2P0t\ncisJK9lUK+OHCTLbUePbQ9JltWKNR1cHqQiD4YhXXjsL4IFDt912m09PUIUis8ptOi4Tngsp/IQo\n8rFPGbgRTUTGhCq0v3gIbL2o0ioCpG+ghoaRzZlMR33SkS2oledsbpqVObS/CyGIpUvrE74aS6c1\nw/Ix45o+dOgwR5cNt5B33wnK1XEyq/v8hVXixCiJkU4RY3MNGQlyK4JkUuP4nSbxZ6s/ZGXViJWV\nq2t+HOXqFzualbtRtV52KVaklCTCBdFGvH7O4ENrdfO8Dhw8QNP6X9JxVsGPONEwSjOkdeVHYncO\ncAusjGrhKxWVs0PrgszGELIsZWAjhGF5HlfUK0mSMrKYKxrWmpidmfVa+HAw5PJVI2KSWuTD28Oe\njV/0hmRW1HRqgoMd87jm5mYoXMOTekLNgnJqSVKJsIJzrJlt8gY2/o0ar2zb67rjQgsszVLG1sm2\ncs3cU78/9HjONEBJqbzwlko26iNtKL+R1BDxzV/5RGRMqEJvJJUvAp4ELmitf9j26/wcsAB8DfhJ\nrS3G/AaktSYbp4YlOri9UuQWuhbJas+HoV0RSVJnesZ063UJMtiquADD0ZiGZZ1TUx2vmJ5++RXW\nrUY+GG35AJjr/JvEie/Kuzg3Tfsuk419sD1Ls2msjP5g5L2FZ1991Xf0dSjwmsD33Kz6HkpQTPh9\np0avZp/STyF81RhwxdlCg8WVT8iygjS1XAH88laq8MjtPE2R1oor4hj5FhYd+3lM5ve0/fufAf9K\na/05IcS/A34a+Le7nkVrA2jRDv83QhdGV2jUY5pN82JrjRpbfbMdEfvqbe7BFSovIflBNthg0Gc8\nNi9r5eo1b50UKmduzrijneaOKM3Y0aBHrW6xlp1ZlmtlUm/LTo4kqQU1H12tS0mkr2+rtC33ddfH\nstNxBO2dwnG7pOVLly7T2zJjG43HJHGpbwxt2F8XGbW46hS7Ge01t/Mo8FeB/2D/FsAPAL9jd/kN\nJuUAviNorxziXwP/BLD+XBaADa21M2rPY2pG3JSEECS1moXQuzT8lKHrvznT4YAt4FFvNKhtGoti\nqzdgYK0LFxUsisIXGqkFK3djY8PjFqUQ3Ha7Gdbi4kEOW9zirOUU66vrDKwr+urVK7z0sik1GEUJ\n7Smzz9133sXCkgkmrfUGPPnM85V7UkUBHkleBNHMag/P7f4HKWUFAb0Td9mujDq3vlO2z545S8dC\n76IYpqfa9vchdcsV6knpywgr9NyI9pLs+8PAVa3114QQ37/b/jscH5QDSCg0SG1MIAAZS7AZRzKO\nPAi0KFTgvNG+SotDHpnEYevFq5X9q/r9gWsfTrvTotU2Osf8/BwLCyYW0LJh5OFgRNNWty+UZmXV\naO/xq6/StFXmlBDMWKul1enwyCMP+7ECrKys0LXpfWEn3m3P4Lpt27volRMJtkdG3TkcWsyVJLg6\nvMpgYMY/Nz9Lx2JGR8MhYysyalEzSA7eZTaw92TfvyaE+CGggdEhPgPMCiFiyyWOYhrCX0da688C\nnwVotVp7F6YTuiW0l2TfXwJ+CcByiH+stf4bQoj/Bvw4xtLYUzkApTTDcUotEjRsXKHVbJPUy0JY\na9ZfX+QbvtBYGrR1dkspihO/yrq9Lc9+o6hs6ooWbHWNqLl06bJXxlo2v3I4GFDYPM9mqwHSlTbs\n8Y1vPgvAmXOvewvm+PHjfOyj3w/AyZMGyv87n/89r7gCvpuPfV47PIMwHT9UPEPsR/l7mIDs9yX8\n7j5FmbagMrSyubCqFjSO0+ySp/Om/BC/CPxDIcRpjE7xa2/iXBN6h9Ab8lRqrR8DHrPfXwXe98aO\nV2TpiKiWIKSR7UlS86XyxmlKr2dWdH8wrJQr9LWlguIXLuaf55lPi5tqd/w+g8GQlRVT4KPfH/iA\nz8GDBh4XxwlN6/JuNBteTxmlI5+ZneaFP67VavPoI++pnKMelPnb3urZUdiQrSjKNV16NqsmqlvF\nUu5svvpP+89tczA9pYJUSVHVRd5RuZ2gkSpFBI0x07xgvGUmQZZlFSxg1zqN6vU6ixbj6OjatWuM\n3ItqNpmZNqUIp6enffr+2toaQ6uRj0ZDpm2irWuTND017ceyvrrOyPo9ao06d95hIqJTM9NcuWLq\nTfX6A5540tSnWrXuY1cvAqr1nK6PfLrvJZgmrJBTtkRSQVqCqNTICJOfodqklbDSLdJ3L6w0gEMj\n3mxZwgl9d9G+RzsFprKKLwYipFcYi0L57PBWq+nZXpKU9ZPcKonjmJr9vdlo+lXfbDb9PkkSMR67\nOS8ZDc11Vldtbaf+gM0N49fY6nYZWZd3a2qKactxlpaWfDR25epVvvENo2xevmy4xtbWlh/b9l6d\nO/X5CBdomR9qxmeeQdk4frsvw5nWbasUH1hc8AVPIilIPAqv7EGqKV3dSRy/8xJ1pDBFy5Ogkn3Y\nFNU5m1qtln8pRjt2UPfyobgHE76IPC8dVjMz0zQbrsJ9B+ve5+WXXgNgPO6Tjo1ISdOxrysRJQl9\ni9Aaj8fMzrjoaZ8LtkTR1atmQqRZXrEEdkq3FyKMhF5vNZh7LydPmLgUTjC3cI4cMQ62hx56iENW\nl7l29QprqwZVPhr1SS1838a/pSUAAA69SURBVMDzXd5rQq02qSAzoTdA+ysypDQ4wDgu6zkrFRTk\nLl21YT2kPC+8BeC2TU9P+5k/Go0CDpHhrPN6vUHdVoip1zp0bcnAK1fNSlq9dsUrc1NTTRYPGhf1\n3Pycxyf2e33fXWc8HntMpbOGojjxiGmjEF7PIZTSXtPfiROYCCf+vndi62Geh0OS33PPPZw6eQKA\nC+fPcenieTu2LuOhGZ8MosLTU1O0bbuoG9G+TggpJa1WG601I4uGUlr5CnJSRoxGjoWnHgEkpSC2\nOodLzul0OoEpV5qGeV5GQbNcBXUvoVYzTz1JXHpY5It9JXGbgwcM+z28uEBUM9fpDwasbxidY2Vl\nhUK5yWYerCY0B6txCEeqKPx2NyGEkIG1EEY1yyo7cVy2bwzbQjugT6Ne55CNz7Q6LQ4dMeiw0XDE\nRVt24Nxrr9C3ycMHF+dot25eDX8iMiZUof3lEEJQqyWM05SxrZ5SaO3BKKaeo9m3KBTKul/juFr3\n2lFYFMMpUXme+9WWZTlCWABJkfvAmAPkdDodmjYhZ25mxqfWDwcjZm0CzzjLuGpFzOXLVzz4xkHX\nsrzwHEkKGbidqSiE25VI1yrC/uXHLGVpkYQtkWZmZrwSff/9pmj63Nyc3zY9O+PdW1mWMz9vosbN\nZpP+hnHOtdut3TL59h9TWdjSOCqojeDyHsJchTKTCUxysCuc5YqEb3qxMxgMvZwMwTIGUWSRQ3le\nFgq1k2dx8SAnT5gC5BrBt14wLZbWNzd57yOmQ2+rnjC0Yqy71fWpAegyydaJERHLsvOwlKWJWeSV\n0gX+rgJwrqs4bJ5LOdHdPS4vL/M93/u9ADz66CMATM9Me11mbm6Wli0jUBQFt91+HID5hXlWr5i4\nY3flEkOb1XYjmoiMCVVo/2tM2SLe3tEkhHcvF0Xut0dR5Fc3SJpN20LZcpA0HTMaOTFR9oHQWvsM\n8k6nQb9vDtjc3GRgfQuudIBx1JjzFboEaWRFTs9WekmS2CtxCHxbJ1c/stVuBmIu99iDWr30r6Sj\nsi6Uo+tFSCk+3NeQkzaaTU7ahrGn3nUvAIOtLb9vrVb3zjmltO/9sbS8TK1mbnL18nmuWP/JjWjf\nM7eUNi/bFe3MsszL9izLmJkxzigppRcPRvO2UHjXoESrSho+2MmjtX8wBw4segdTt9v1pqs7R7/f\n55vfNE3dO1NTHD5sKsw06zU2bB5IlmYkdtbMTM+ytm7MToeJnZ/veDa7sdH13QHr9XppCqfZtu66\nhsJcDF/3IioRTg5KD9Db6vowu3teSZLQtkCeWq3myxxB4etAKKBvLZSrayucv3zuunGENBEZE6rQ\n/nIIZQqJx3FMrVEWCQm1cbeKlSodKmFSju/xGWRJQWl9JEniK61EUenkabXbnm07DqIpHUwKzfSM\nWW1ZlnL1koHeSyE4dPiIPXeTza61VIrShe58Tb1e3zuQDJzOFfuq+e1uDEURWCdSksTOPyC80tvp\ndDh0yPgZ7r33lFdMe9Y5dmjpoC9WJoTwxUOiwLklZEwkXS+OBC0nrusJvQHaVw5RKEW/3yOKY2p2\n9U9NT7NoAzSj4Yjz542JNBgMmZoyKzaKpC/3Px5r+zn2XW/SNCWxQZvO1JSPpK5cu8rAYhzqtRr1\nAwfs+RwKWfgAWpalXLpouMJwMPDm3sHFA0xPm1WY5YrY1u0ZDV3DM+WxB6ZSrC0umqugil7dw/f6\n/S0/ZkdJUqOWGM9oURQeWb548G4+/vGPA3DvqXvZ2jTb+7awae3YUZ/TOhqNvE7VCvpzykjSsSWW\nFheXGffddf94x3d0C+pUmhoQzl5PksTXc5BCMjtrs6pqtRIbiTbFvSGICUT+prMs8zUtm62mz4cc\n9ns+eWV6quP9BS5bKy+0t921Vqxe69vft7yrXMoSCa6VIrGFwjo2JjA/N+dd0FeuXGbkss1GI2Kb\nN5qmI1p2/yPLtolL4CTqbfVYuWYThsZjDtoGsI+852E+8pGPAHDs6DJPP/WUHYernJv4yrp5nnvR\nWw8a1Eqg0zIT+siR20nim8cyJiJjQhXa5/YIklq9TqPRoNMxGIM4julaVthqt7nnXmNr51nO5cum\nHOBoOPJKWWK5SavVquAQPBhFl8jnxQOLPqoqpWB11aTwb2y41ZiyYIuByCjyTd2mZUTLIsHrScKa\n7Rqc5iW2wHUEPnZs2ftDzpw9w3Bk81SjERojdvq9Te62KO3v/bDxNj78wH1e/Dzz9Wf44pcMCx9n\nKY+8x+A2P/TBD7Jom9JLITyXKbVpXTFnw8BaiO52eNOZ+QXELp0R93VCTE1N8X0f+QhxUqPZNDe3\nsb7Ba6+ajKksy7y8FkL6Dna6UN4y8JlKUezlZ5IkZbmAKPLsslGvl/6LJPa+A1eIfHVtvYyBFIos\nN98FYcvpyDsdWu0OS9YaWFgwL2pudpaNTTPOWr3hxzTVafl+3mpxhrvuOg7AsvV1zE53KFIzjqWD\nCzz6qEkAShpt3v++9wKmBbRLTFaq8KLEkQEXld9DDGfpIheBpdVhN6EwERkTqtCeOIQQYhaT6Hs/\nxnz/28CLwG8Bx4EzwCe11us3O8/c/Dw/9slPmd4OdtsLzz3nWfilCxe5esVEFuM4rsDlXCtkl4aX\npplfESGHCOsrjbX26W0z01Ms2+9ty2XOXbjIpUvGlbuxuuqPQ8NwaOH5rTbL88YKWjiw4L2HbtXl\nRcHAeg7jJGFh3qzoQwcOcOyYySs9sLRA24770jlTJ+rFbzzN+pqJQh5aXuajHzPK4z333k8SOVxp\ny/sy4iTyyHN33/VGw+Mr4ri1DW7vbiXID1W7V7XZq8j4DPCHWusfF0LUgBamd+eXtda/IoT4NPBp\nTPLODandavPe974PpZVv/NFptz0U/uxrZ2jY+g9CCLJjxrKo1+t+QjiTcjAY+Mryg8HQx0NUXlC4\nDn6F8j0yZmbmaLasbmHlf5zE9K1ZOhyOOXLERQsVG7ZSba61l8HGRDVPtN83lsqlS5c9TF8rxR3H\njwPw0AP384CtPDt/YN5X2j931gBXzipNZvWb2++4i7/04Q8DcN99D3qIf7fbqzRkdZZNWMvTRYGj\nqKx6VxRlsxWBYN26vF966SUPDr4R7SoyhBAzwIexmVla61RrvQH8CKYMAEzKAXzH0F44xB3ACvAf\nhRDvxlSL+XlgSWt9ye5zGVja6eAw+3t5eZnRYGjK7Vll787b7+TArFmx3c2uLzU4HqclHJ0yOuoh\nZeMh5ywC+rXXXvMRyan5WZ+LqQvlcRVJUvPFxus223ym0/EJPu32DPecNBZOmo55+plvAAaq7zjR\n5ua6VxpdoOn06dOsrJjGsbVajSMPmIby7//QB3n4oYfMWEdDb+2cPGlqZOZF7kFCUzPTLB6w8LfR\n2Dd1a7fLnqFaa5LERmmTMvLrREAIwonjuFKpxiHEv/r4n/lg3o1oLxMiBt4D/JzW+nEhxGcw4sGT\n1lqLMiWJbb/57O8HH3xQ51lGEsfe/Jmfm+fI4WW7r6rA3x0VRdnL2iGWCpUxM2teZqPRpNcz3rv5\n+Tna1oJRSlNkZeU5Z5k2bRW3pUPLLCweBSCpNbn3XgOWybKMo0dNJbtr164xZzX92dkZGhZJ5UzR\nZrNJb8uIj5nZGT7wgQ8A8N73vZ+77rzT7Lu66l/WjBV9DZseACZ87wqKZWnmRUKz2fRiQCnlw/rO\ncqqmH+QV8I3TqbIs82WQLpw/z5lXT3Mz2ouVcR44r7V+3P79O5gJckUIcRjAfl7dw7km9A6nvZQD\nuCyEOCeEuEdr/SKm3/fz9v9PYZrC76kcgCOltY/MDYfDCq7BRThNc7YSjlZC6+r2s8Gxo6ZIWKcz\n7Y9rNpu+3XJRKN8SKctyL6ZcwzOlNPfZyKEQwiuuACdOGHh7mqYVFLRbsS6OMhwOPPeqJQlz88bR\ndWBhwccr4qSMMOYeRT0ok4+KonQwBXxWCOGdbCG+suwMWOZthpaWwZiaaw8GA+9an5+d5egRE7k9\ne+4iO9FerYyfA37TWhivAn8Lw11+Wwjx08BZ4JN7OZFLWnU3FTYXDRNat+cnhNldYB6AY99TU9Ne\nlsZx7JOpVVH4oFKWpV42OxBOvV73E0mpEiofx7Hvz1GlEpRTwuq3h5PLetMuOz0EBrsWi1nwgsO2\nikIIhCrH4Y4NM7d2Kj90o7S/8Tj1dSNazSZzwaTfifY0IbTWTwOP7vDTR/dy/IT+4pB4IyXz3vTF\nhFgB+sC1fbvo3ukA78xxwdszttu11ovbN+7rhAAQQjyptd6J29xSeqeOC/Z3bJNYxoQqNJkQE6rQ\nrZgQn70F19wLvVPHBfs4tn3XISb0zqaJyJhQhfZtQgghPi6EeFEIcdqGy28ZCSGOCSH+txDieSHE\nc0KIn7fb/6kQ4oIQ4mn7/4duwdjOCCGetdd/0m6bF0L8iRDiZfs597Zdfz9Ehu218RLwg5jYyBPA\nT2itn7/pgW/feA4Dh7XWTwkhpjAR3E9gvK09rfW/uBXjsmM7Azyqtb4WbPvnwFqAPZnTWt8Ue/Lt\n0n5xiPcBp7XWr9omK5/D4CluCWmtL2mtn7LftzB9QHat5n8Lad+wJ/s1IZaBMMt0T+0U9oOEEMeB\nhwEXzf1ZIcQ3hBC//nay5puQBv5YCPE1iyWBPWJP3gr6rlYqhRAd4HeBX9BadzEdge4CHgIuAf/y\nFgzre7XW7wH+CvAPhBAfDn/URsa/bXJ+vybEBeBY8PcN2ynsFwkhEsxk+E2t9ecBtNZXtNaFNvHi\nf88brOX9VpDW+oL9vAp8wY5h37An+zUhngBOCCHusCH0TwFf3KdrX0e2RdSvAS9orX812H442O1H\ngW/u87jaVslFCNEG/rIdwxcxmBN4g9iTN0r7kqijtc6FED8L/BGmlOuva61vDu57e+l7gJ8EnhVC\nPG23/TLwE0KIhzAs+Qzwd/d5XEvAFyyuIQb+i9b6D4UQT/BtYE++HZp4KidUoe9qpXJC19NkQkyo\nQpMJMaEKTSbEhCo0mRATqtBkQkyoQpMJMaEKTSbEhCr0/wFz0wvMhCHynAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZSXSc3Vo1-t",
        "colab_type": "text"
      },
      "source": [
        "### Assignment: Define the tensorflow model\n",
        "\n",
        "The model should have the following layers\n",
        "- input later\n",
        "- conv layer 1 with 32 filters of kernel  size[5,5],\n",
        "- pooling layer 1 with pool size[2,2] and stride 2\n",
        "- conv layer 2 with 64 filters of kernel  size[5,5],\n",
        "- pooling layer 2 with pool size[2,2] and stride 2\n",
        "- dense layer whose output size is fixed in the hyper parameter: fc_size=32\n",
        "- drop out layer with droput probability 0.4\n",
        "- predict the class by doing a softmax on the output of the dropout layers\n",
        "\n",
        "Training\n",
        "- For training define the loss function and minimize it\n",
        "- For evaluation calculate the accuracy\n",
        "\n",
        "Reading Material\n",
        "- For ideas look at tensorflow layers tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aZBDDF2o1-t",
        "colab_type": "text"
      },
      "source": [
        "### The cnn_model_fn has to be defined here by the student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGE1vxnNo1-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model_fn(features, labels, mode):\n",
        "    # Input Layer\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, img_size, img_size, num_channels])\n",
        "\n",
        "    # Convolutional Layer #1\n",
        "    conv1 = tf.layers.conv2d(\n",
        "        inputs=input_layer,\n",
        "        filters=32,\n",
        "        kernel_size=[5, 5],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    # Pooling Layer #1\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    # Convolutional Layer #2 and Pooling Layer #2\n",
        "    conv2 = tf.layers.conv2d(\n",
        "        inputs=pool1,\n",
        "        filters=64,\n",
        "        kernel_size=[5, 5],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    # Flattening pooling layer before connecting fully connected layer\n",
        "    layer_shape = pool2.get_shape()\n",
        "    num_features = layer_shape[1:4].num_elements();\n",
        "    print( \" Total features in pool2 layer should be 8*8*64 and it is found to be :\" ,num_features)\n",
        "    \n",
        "    # Dense Layer\n",
        "    pool2_flat = tf.reshape(pool2, [-1, num_features])\n",
        "    dense = tf.layers.dense(inputs=pool2_flat, units=fc_size, activation=tf.nn.relu)\n",
        "    dropout = tf.layers.dropout(\n",
        "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    # Logits Layer\n",
        "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
        "\n",
        "    predictions = {\n",
        "        # Generate predictions (for PREDICT and EVAL mode)\n",
        "        \"classes\": tf.argmax(input=logits, axis=1),\n",
        "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
        "        # `logging_hook`.\n",
        "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
        "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
        "\n",
        "    # Configure the Training Op (for TRAIN mode)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    # Add evaluation metrics (for EVAL mode)\n",
        "    eval_metric_ops = {\n",
        "        \"accuracy\": tf.metrics.accuracy(\n",
        "            labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmrvznRFo1-x",
        "colab_type": "text"
      },
      "source": [
        "### Run the tensorflow model\n",
        "\n",
        "This section will use the model defined by the student and run the training and evaluation step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQD-qZWBo1-y",
        "colab_type": "code",
        "outputId": "c329fd7d-ab89-44f3-f212-4c4ebcaa690d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#X_train = np.array((X_train/255.0),dtype=np.float16)\n",
        "#X_test = np.array((X_test/255.0), dtype=np.float16)\n",
        "X_train = np.array((X_train/255.0),dtype=np.float32)\n",
        "X_test = np.array((X_test/255.0), dtype=np.float32)\n",
        "\n",
        "pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model\")\n",
        "#pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n",
        "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
        "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_train}, y=y_train, batch_size=10,\n",
        "                                                      num_epochs=None, shuffle=True)\n",
        "pets_classifier.train(input_fn=train_input_fn, steps=num_steps, hooks=[logging_hook])\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_test}, y=y_test, num_epochs=1,shuffle=False)\n",
        "eval_results = pets_classifier.evaluate(input_fn=eval_input_fn)\n",
        "print(eval_results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0ccaa2e160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            " Total features in pool2 layer should be 8*8*64 and it is found to be : 4096\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt-2200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2200 into /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:probabilities = [[0.99932027 0.00067971]\n",
            " [0.99966466 0.00033538]\n",
            " [0.99656314 0.00343683]\n",
            " [0.9922401  0.00775997]\n",
            " [0.9995333  0.00046677]\n",
            " [0.9960884  0.00391162]\n",
            " [0.9999726  0.00002745]\n",
            " [0.99975103 0.00024898]\n",
            " [0.9997819  0.00021808]\n",
            " [0.98712885 0.0128712 ]\n",
            " [0.9993319  0.00066804]\n",
            " [0.97937095 0.020629  ]\n",
            " [0.9977387  0.00226131]\n",
            " [0.9995857  0.00041427]\n",
            " [0.9978485  0.00215153]\n",
            " [0.9997603  0.00023968]\n",
            " [0.99275756 0.00724246]\n",
            " [0.9997701  0.00022994]\n",
            " [0.99862504 0.00137498]\n",
            " [0.99994314 0.0000569 ]\n",
            " [0.9999641  0.00003591]\n",
            " [0.99981004 0.00018997]\n",
            " [0.99995065 0.0000494 ]\n",
            " [0.9897662  0.01023376]\n",
            " [0.9735727  0.02642732]\n",
            " [0.988842   0.01115793]\n",
            " [0.9999895  0.00001053]\n",
            " [0.99914813 0.00085185]\n",
            " [0.9999361  0.0000639 ]\n",
            " [0.99952054 0.00047948]\n",
            " [0.99875283 0.00124718]\n",
            " [0.99993825 0.00006178]\n",
            " [0.97244555 0.0275544 ]\n",
            " [0.99991894 0.00008102]\n",
            " [0.97989804 0.02010202]\n",
            " [0.9991948  0.00080521]\n",
            " [0.94841397 0.05158601]\n",
            " [0.99954    0.00046007]\n",
            " [0.97704655 0.02295342]\n",
            " [0.9998816  0.00011835]\n",
            " [0.9968759  0.00312404]\n",
            " [0.999998   0.00000202]\n",
            " [0.999995   0.00000497]\n",
            " [0.9976019  0.00239815]\n",
            " [0.97861516 0.02138485]\n",
            " [0.9984785  0.00152149]\n",
            " [0.9995485  0.00045143]\n",
            " [0.99991953 0.00008042]\n",
            " [0.99996126 0.00003876]\n",
            " [0.99997747 0.00002253]\n",
            " [0.99046963 0.00953039]\n",
            " [0.9944325  0.00556746]\n",
            " [0.9999877  0.00001225]\n",
            " [0.9997286  0.00027138]\n",
            " [0.99897313 0.00102683]\n",
            " [0.9982065  0.00179352]\n",
            " [0.999894   0.00010593]\n",
            " [0.9987122  0.00128782]\n",
            " [0.99556476 0.00443526]\n",
            " [0.9992841  0.00071593]\n",
            " [0.9973852  0.00261475]\n",
            " [0.9895963  0.01040371]\n",
            " [0.99892455 0.00107545]\n",
            " [0.99991584 0.00008411]\n",
            " [0.9999999  0.00000016]\n",
            " [0.9997733  0.00022663]\n",
            " [0.999892   0.00010795]\n",
            " [0.9987122  0.00128783]\n",
            " [0.99996185 0.00003811]\n",
            " [0.90976113 0.09023891]\n",
            " [0.99662435 0.00337565]\n",
            " [0.99999905 0.00000096]\n",
            " [0.999884   0.00011595]\n",
            " [0.9999285  0.00007153]\n",
            " [0.9999752  0.00002477]\n",
            " [0.9999846  0.00001539]\n",
            " [0.99889684 0.00110314]\n",
            " [0.99992335 0.0000766 ]\n",
            " [0.9890076  0.01099248]\n",
            " [0.9996711  0.00032887]\n",
            " [0.9974962  0.00250384]\n",
            " [0.99979156 0.00020851]\n",
            " [0.9992293  0.00077068]\n",
            " [0.99968886 0.00031121]\n",
            " [0.9997683  0.00023171]\n",
            " [0.9990006  0.00099941]\n",
            " [0.99995613 0.00004388]\n",
            " [0.9977792  0.00222083]\n",
            " [0.9999938  0.00000621]\n",
            " [0.9999727  0.00002726]\n",
            " [0.99978274 0.00021724]\n",
            " [0.9994105  0.00058953]\n",
            " [0.9977575  0.00224258]\n",
            " [0.9998374  0.0001626 ]\n",
            " [0.99999666 0.0000033 ]\n",
            " [0.9999629  0.00003707]\n",
            " [0.9998801  0.00011986]\n",
            " [0.9999809  0.00001906]\n",
            " [0.99985254 0.00014747]\n",
            " [0.9997545  0.00024546]]\n",
            "INFO:tensorflow:loss = 5.0488753, step = 2201\n",
            "INFO:tensorflow:probabilities = [[0.35440847 0.64559156]\n",
            " [0.44692963 0.5530704 ]\n",
            " [0.44259    0.55741   ]\n",
            " [0.4903037  0.5096963 ]\n",
            " [0.5473138  0.45268613]\n",
            " [0.5342014  0.4657986 ]\n",
            " [0.4366484  0.5633516 ]\n",
            " [0.45211178 0.5478882 ]\n",
            " [0.5306637  0.46933627]\n",
            " [0.45909464 0.5409053 ]\n",
            " [0.49248025 0.5075197 ]\n",
            " [0.51652056 0.48347947]\n",
            " [0.4164835  0.5835165 ]\n",
            " [0.53794396 0.46205598]\n",
            " [0.43421552 0.56578445]\n",
            " [0.23471345 0.7652866 ]\n",
            " [0.74137837 0.25862166]\n",
            " [0.46364692 0.5363531 ]\n",
            " [0.44776025 0.5522398 ]\n",
            " [0.34468842 0.6553116 ]\n",
            " [0.45631927 0.54368067]\n",
            " [0.3629553  0.6370447 ]\n",
            " [0.39620394 0.6037961 ]\n",
            " [0.4608503  0.5391497 ]\n",
            " [0.8657351  0.13426493]\n",
            " [0.4685208  0.53147924]\n",
            " [0.70248866 0.2975113 ]\n",
            " [0.5142852  0.48571476]\n",
            " [0.48722723 0.51277274]\n",
            " [0.5636758  0.43632412]\n",
            " [0.33449575 0.6655043 ]\n",
            " [0.4844791  0.5155209 ]\n",
            " [0.7028136  0.29718637]\n",
            " [0.44326156 0.55673844]\n",
            " [0.5266195  0.47338054]\n",
            " [0.3473718  0.65262824]\n",
            " [0.53045607 0.46954396]\n",
            " [0.5608083  0.43919164]\n",
            " [0.38350114 0.6164988 ]\n",
            " [0.5229986  0.4770015 ]\n",
            " [0.51772135 0.48227865]\n",
            " [0.30531418 0.6946858 ]\n",
            " [0.49160892 0.50839114]\n",
            " [0.5910025  0.40899748]\n",
            " [0.43203717 0.56796277]\n",
            " [0.5906295  0.40937045]\n",
            " [0.36300227 0.63699776]\n",
            " [0.35152072 0.6484793 ]\n",
            " [0.4913232  0.5086768 ]\n",
            " [0.44985524 0.55014473]\n",
            " [0.41443917 0.5855608 ]\n",
            " [0.42987156 0.5701284 ]\n",
            " [0.6308254  0.36917457]\n",
            " [0.33212158 0.66787845]\n",
            " [0.7145143  0.28548566]\n",
            " [0.46666795 0.53333205]\n",
            " [0.50010353 0.4998965 ]\n",
            " [0.4619261  0.53807384]\n",
            " [0.5116907  0.48830935]\n",
            " [0.6057295  0.3942704 ]\n",
            " [0.41246393 0.5875361 ]\n",
            " [0.48589215 0.5141079 ]\n",
            " [0.6386621  0.36133796]\n",
            " [0.3939499  0.6060501 ]\n",
            " [0.3825943  0.6174058 ]\n",
            " [0.45916554 0.5408344 ]\n",
            " [0.41530713 0.58469284]\n",
            " [0.5251324  0.47486758]\n",
            " [0.35879123 0.64120877]\n",
            " [0.33207935 0.66792065]\n",
            " [0.49039707 0.5096029 ]\n",
            " [0.5323396  0.46766043]\n",
            " [0.31941384 0.68058616]\n",
            " [0.4720241  0.5279759 ]\n",
            " [0.5816227  0.41837725]\n",
            " [0.33848944 0.6615106 ]\n",
            " [0.5599277  0.44007227]\n",
            " [0.3749431  0.6250569 ]\n",
            " [0.41593271 0.5840673 ]\n",
            " [0.58437675 0.41562325]\n",
            " [0.4914183  0.5085817 ]\n",
            " [0.44727343 0.55272657]\n",
            " [0.36644438 0.6335557 ]\n",
            " [0.38216048 0.6178395 ]\n",
            " [0.5057708  0.49422917]\n",
            " [0.4757048  0.5242953 ]\n",
            " [0.41207543 0.5879246 ]\n",
            " [0.43961513 0.5603848 ]\n",
            " [0.5554969  0.44450316]\n",
            " [0.5444538  0.45554617]\n",
            " [0.62388897 0.376111  ]\n",
            " [0.5162653  0.4837347 ]\n",
            " [0.5625973  0.43740276]\n",
            " [0.45079148 0.5492085 ]\n",
            " [0.39156097 0.60843897]\n",
            " [0.32382712 0.6761729 ]\n",
            " [0.4877452  0.5122548 ]\n",
            " [0.4062191  0.5937808 ]\n",
            " [0.29959026 0.7004097 ]\n",
            " [0.40243998 0.59756005]] (14.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.43982\n",
            "INFO:tensorflow:probabilities = [[0.60701895 0.39298105]\n",
            " [0.32173875 0.6782613 ]\n",
            " [0.16069147 0.8393085 ]\n",
            " [0.2061426  0.7938574 ]\n",
            " [0.23592763 0.7640724 ]\n",
            " [0.406552   0.59344804]\n",
            " [0.0996689  0.9003311 ]\n",
            " [0.18674481 0.81325513]\n",
            " [0.2069808  0.79301924]\n",
            " [0.40563583 0.59436417]\n",
            " [0.44709432 0.5529057 ]\n",
            " [0.3529081  0.64709187]\n",
            " [0.39047483 0.6095252 ]\n",
            " [0.47782058 0.5221794 ]\n",
            " [0.4458336  0.55416644]\n",
            " [0.47495866 0.52504134]\n",
            " [0.26637155 0.7336284 ]\n",
            " [0.36211488 0.63788515]\n",
            " [0.41326714 0.58673286]\n",
            " [0.4132775  0.5867225 ]\n",
            " [0.17020448 0.82979554]\n",
            " [0.27385074 0.7261492 ]\n",
            " [0.28293467 0.7170654 ]\n",
            " [0.2321106  0.7678894 ]\n",
            " [0.18706441 0.81293553]\n",
            " [0.30847406 0.69152594]\n",
            " [0.41382244 0.5861775 ]\n",
            " [0.43725535 0.5627446 ]\n",
            " [0.24707893 0.75292104]\n",
            " [0.3742216  0.6257784 ]\n",
            " [0.4694823  0.53051776]\n",
            " [0.42763597 0.572364  ]\n",
            " [0.4020252  0.5979748 ]\n",
            " [0.31674823 0.68325186]\n",
            " [0.5628543  0.43714568]\n",
            " [0.2811971  0.71880287]\n",
            " [0.41511303 0.58488697]\n",
            " [0.28395128 0.7160487 ]\n",
            " [0.20663598 0.793364  ]\n",
            " [0.23628318 0.7637168 ]\n",
            " [0.21828094 0.7817191 ]\n",
            " [0.15257722 0.8474227 ]\n",
            " [0.2742667  0.7257333 ]\n",
            " [0.13214159 0.86785835]\n",
            " [0.23609562 0.7639044 ]\n",
            " [0.25147647 0.7485236 ]\n",
            " [0.37657318 0.6234268 ]\n",
            " [0.31519628 0.6848037 ]\n",
            " [0.31072113 0.6892789 ]\n",
            " [0.2282193  0.7717807 ]\n",
            " [0.5690476  0.4309524 ]\n",
            " [0.28997782 0.71002215]\n",
            " [0.5626528  0.43734723]\n",
            " [0.394842   0.605158  ]\n",
            " [0.6250271  0.3749729 ]\n",
            " [0.4035961  0.5964039 ]\n",
            " [0.3335608  0.6664392 ]\n",
            " [0.35125443 0.6487456 ]\n",
            " [0.31561363 0.6843864 ]\n",
            " [0.2763738  0.72362614]\n",
            " [0.17564368 0.8243563 ]\n",
            " [0.4961783  0.5038217 ]\n",
            " [0.301628   0.69837195]\n",
            " [0.3317021  0.6682979 ]\n",
            " [0.3481921  0.6518079 ]\n",
            " [0.29769197 0.7023081 ]\n",
            " [0.23231968 0.76768035]\n",
            " [0.38213408 0.6178659 ]\n",
            " [0.31526676 0.6847332 ]\n",
            " [0.43977588 0.5602241 ]\n",
            " [0.36413518 0.6358648 ]\n",
            " [0.39174053 0.6082595 ]\n",
            " [0.5654322  0.4345679 ]\n",
            " [0.34194016 0.65805984]\n",
            " [0.18311392 0.81688607]\n",
            " [0.32475019 0.6752499 ]\n",
            " [0.4243142  0.5756858 ]\n",
            " [0.5473053  0.45269477]\n",
            " [0.4549872  0.5450128 ]\n",
            " [0.48524323 0.51475674]\n",
            " [0.46821535 0.5317847 ]\n",
            " [0.3996594  0.6003406 ]\n",
            " [0.47282922 0.5271708 ]\n",
            " [0.14981103 0.850189  ]\n",
            " [0.39833516 0.6016648 ]\n",
            " [0.24638756 0.75361246]\n",
            " [0.24249825 0.7575018 ]\n",
            " [0.26541647 0.73458356]\n",
            " [0.26777723 0.7322228 ]\n",
            " [0.16101699 0.83898306]\n",
            " [0.22527125 0.7747288 ]\n",
            " [0.2346414  0.76535857]\n",
            " [0.2958985  0.7041015 ]\n",
            " [0.3258555  0.6741445 ]\n",
            " [0.46700564 0.53299433]\n",
            " [0.28884628 0.71115375]\n",
            " [0.36162996 0.6383701 ]\n",
            " [0.24910155 0.7508985 ]\n",
            " [0.21763574 0.78236425]\n",
            " [0.20092842 0.7990716 ]] (14.467 sec)\n",
            "INFO:tensorflow:loss = 0.60377264, step = 2301 (29.077 sec)\n",
            "INFO:tensorflow:probabilities = [[0.39878616 0.6012138 ]\n",
            " [0.20591643 0.79408354]\n",
            " [0.33799934 0.6620007 ]\n",
            " [0.15333153 0.8466684 ]\n",
            " [0.15451756 0.84548247]\n",
            " [0.53017014 0.46982977]\n",
            " [0.27728888 0.7227111 ]\n",
            " [0.3455729  0.6544271 ]\n",
            " [0.44621947 0.5537805 ]\n",
            " [0.14897743 0.8510226 ]\n",
            " [0.2622116  0.7377884 ]\n",
            " [0.17511207 0.82488793]\n",
            " [0.23402588 0.7659741 ]\n",
            " [0.10164896 0.898351  ]\n",
            " [0.35101023 0.64898974]\n",
            " [0.3697849  0.6302151 ]\n",
            " [0.308204   0.691796  ]\n",
            " [0.26513627 0.73486376]\n",
            " [0.25938973 0.74061024]\n",
            " [0.21874899 0.781251  ]\n",
            " [0.25215834 0.74784166]\n",
            " [0.4803103  0.51968974]\n",
            " [0.25652403 0.743476  ]\n",
            " [0.28515705 0.714843  ]\n",
            " [0.45966148 0.54033846]\n",
            " [0.2539119  0.746088  ]\n",
            " [0.46101284 0.5389871 ]\n",
            " [0.19562125 0.80437875]\n",
            " [0.2863556  0.7136444 ]\n",
            " [0.52019423 0.47980577]\n",
            " [0.379754   0.620246  ]\n",
            " [0.13991402 0.860086  ]\n",
            " [0.27447954 0.7255205 ]\n",
            " [0.20804444 0.7919556 ]\n",
            " [0.41183603 0.5881639 ]\n",
            " [0.3891253  0.6108747 ]\n",
            " [0.4725036  0.5274964 ]\n",
            " [0.3209546  0.67904544]\n",
            " [0.21809158 0.78190845]\n",
            " [0.18091488 0.8190851 ]\n",
            " [0.24888557 0.7511144 ]\n",
            " [0.0762857  0.9237143 ]\n",
            " [0.200539   0.79946107]\n",
            " [0.417597   0.58240294]\n",
            " [0.3104652  0.6895348 ]\n",
            " [0.4553935  0.5446065 ]\n",
            " [0.24674985 0.7532502 ]\n",
            " [0.5615945  0.43840554]\n",
            " [0.20973946 0.79026055]\n",
            " [0.25264546 0.74735457]\n",
            " [0.31218284 0.6878171 ]\n",
            " [0.24127841 0.7587216 ]\n",
            " [0.22473282 0.7752672 ]\n",
            " [0.36216953 0.6378305 ]\n",
            " [0.18830708 0.81169295]\n",
            " [0.31032246 0.6896775 ]\n",
            " [0.18280268 0.8171973 ]\n",
            " [0.4535271  0.54647297]\n",
            " [0.3749524  0.6250476 ]\n",
            " [0.41126737 0.58873266]\n",
            " [0.1141478  0.8858523 ]\n",
            " [0.25988513 0.7401148 ]\n",
            " [0.29759225 0.7024078 ]\n",
            " [0.2965492  0.70345074]\n",
            " [0.19259883 0.8074011 ]\n",
            " [0.25255617 0.74744385]\n",
            " [0.37964043 0.62035954]\n",
            " [0.3841978  0.6158022 ]\n",
            " [0.41793665 0.5820633 ]\n",
            " [0.29217398 0.7078261 ]\n",
            " [0.14676283 0.85323715]\n",
            " [0.19790153 0.80209845]\n",
            " [0.3980477  0.6019523 ]\n",
            " [0.31267267 0.6873274 ]\n",
            " [0.35465467 0.6453453 ]\n",
            " [0.23151504 0.76848495]\n",
            " [0.40837297 0.591627  ]\n",
            " [0.19003764 0.80996233]\n",
            " [0.37201837 0.6279816 ]\n",
            " [0.27941385 0.7205862 ]\n",
            " [0.21053138 0.78946865]\n",
            " [0.5703797  0.4296203 ]\n",
            " [0.24401937 0.7559807 ]\n",
            " [0.09329842 0.90670156]\n",
            " [0.40369418 0.59630585]\n",
            " [0.34618896 0.6538111 ]\n",
            " [0.3723805  0.6276195 ]\n",
            " [0.37077624 0.6292238 ]\n",
            " [0.46681964 0.5331803 ]\n",
            " [0.51739335 0.48260665]\n",
            " [0.48176113 0.51823884]\n",
            " [0.2351363  0.76486367]\n",
            " [0.2506466  0.7493534 ]\n",
            " [0.3366588  0.6633412 ]\n",
            " [0.19588317 0.80411685]\n",
            " [0.43331385 0.5666862 ]\n",
            " [0.11842567 0.88157433]\n",
            " [0.2740201  0.72597986]\n",
            " [0.52424085 0.47575915]\n",
            " [0.23030858 0.7696914 ]] (14.491 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.45392\n",
            "INFO:tensorflow:probabilities = [[0.30700478 0.6929952 ]\n",
            " [0.337996   0.66200405]\n",
            " [0.36695832 0.6330417 ]\n",
            " [0.21903302 0.78096694]\n",
            " [0.40920117 0.59079885]\n",
            " [0.2737495  0.7262505 ]\n",
            " [0.19658224 0.8034178 ]\n",
            " [0.11003502 0.889965  ]\n",
            " [0.27805343 0.7219466 ]\n",
            " [0.27758107 0.722419  ]\n",
            " [0.3904051  0.60959494]\n",
            " [0.32125607 0.6787439 ]\n",
            " [0.19924276 0.8007572 ]\n",
            " [0.46512568 0.5348744 ]\n",
            " [0.14923772 0.8507623 ]\n",
            " [0.23458733 0.7654126 ]\n",
            " [0.30581293 0.6941871 ]\n",
            " [0.24512598 0.754874  ]\n",
            " [0.24565962 0.75434035]\n",
            " [0.48548546 0.5145146 ]\n",
            " [0.32041407 0.679586  ]\n",
            " [0.28892872 0.71107125]\n",
            " [0.4764859  0.52351403]\n",
            " [0.34978887 0.65021116]\n",
            " [0.23144867 0.76855135]\n",
            " [0.30777484 0.69222516]\n",
            " [0.37553707 0.62446296]\n",
            " [0.2795403  0.7204597 ]\n",
            " [0.31228828 0.6877117 ]\n",
            " [0.14097443 0.85902554]\n",
            " [0.09513105 0.9048689 ]\n",
            " [0.3769007  0.6230992 ]\n",
            " [0.22058244 0.7794176 ]\n",
            " [0.35333163 0.6466684 ]\n",
            " [0.23179333 0.76820666]\n",
            " [0.16113041 0.83886963]\n",
            " [0.5680505  0.4319495 ]\n",
            " [0.35315073 0.6468493 ]\n",
            " [0.10242543 0.89757454]\n",
            " [0.29706666 0.7029333 ]\n",
            " [0.59170544 0.40829453]\n",
            " [0.3111889  0.688811  ]\n",
            " [0.16686028 0.8331397 ]\n",
            " [0.3438934  0.65610665]\n",
            " [0.10226624 0.89773375]\n",
            " [0.17097811 0.8290219 ]\n",
            " [0.11791898 0.88208103]\n",
            " [0.29732656 0.70267344]\n",
            " [0.39452234 0.6054777 ]\n",
            " [0.16167809 0.8383219 ]\n",
            " [0.35935882 0.64064115]\n",
            " [0.3028485  0.6971515 ]\n",
            " [0.35039768 0.64960235]\n",
            " [0.41439435 0.5856057 ]\n",
            " [0.41771683 0.5822832 ]\n",
            " [0.31060728 0.68939275]\n",
            " [0.16703661 0.8329634 ]\n",
            " [0.19267231 0.8073277 ]\n",
            " [0.15382856 0.8461714 ]\n",
            " [0.13708922 0.8629108 ]\n",
            " [0.44963518 0.55036485]\n",
            " [0.21646258 0.7835374 ]\n",
            " [0.2793346  0.7206654 ]\n",
            " [0.21345745 0.78654253]\n",
            " [0.34370124 0.6562987 ]\n",
            " [0.23557311 0.7644269 ]\n",
            " [0.43193558 0.56806445]\n",
            " [0.46862966 0.5313703 ]\n",
            " [0.14914735 0.8508526 ]\n",
            " [0.37400964 0.6259904 ]\n",
            " [0.15889233 0.84110767]\n",
            " [0.32890853 0.6710915 ]\n",
            " [0.33839253 0.66160756]\n",
            " [0.37962273 0.62037724]\n",
            " [0.3308878  0.66911227]\n",
            " [0.3099397  0.69006026]\n",
            " [0.26302454 0.73697543]\n",
            " [0.26305807 0.73694193]\n",
            " [0.2833267  0.7166733 ]\n",
            " [0.20586996 0.79413   ]\n",
            " [0.2546928  0.74530715]\n",
            " [0.2981551  0.7018449 ]\n",
            " [0.345298   0.654702  ]\n",
            " [0.49761105 0.502389  ]\n",
            " [0.41767904 0.5823209 ]\n",
            " [0.4723204  0.5276796 ]\n",
            " [0.3246522  0.6753478 ]\n",
            " [0.2641096  0.73589045]\n",
            " [0.3051094  0.69489056]\n",
            " [0.19475241 0.8052476 ]\n",
            " [0.2366357  0.7633643 ]\n",
            " [0.32460698 0.675393  ]\n",
            " [0.31093222 0.6890677 ]\n",
            " [0.28868514 0.7113148 ]\n",
            " [0.3160668  0.6839332 ]\n",
            " [0.39371574 0.6062842 ]\n",
            " [0.23896319 0.7610369 ]\n",
            " [0.14735821 0.8526418 ]\n",
            " [0.4063648  0.5936352 ]\n",
            " [0.42452917 0.57547086]] (14.463 sec)\n",
            "INFO:tensorflow:loss = 0.6088148, step = 2401 (28.952 sec)\n",
            "INFO:tensorflow:probabilities = [[0.11823518 0.8817648 ]\n",
            " [0.2118721  0.7881279 ]\n",
            " [0.22568487 0.7743151 ]\n",
            " [0.19456157 0.8054384 ]\n",
            " [0.3552413  0.6447587 ]\n",
            " [0.40620625 0.59379375]\n",
            " [0.4113193  0.58868074]\n",
            " [0.30037495 0.6996251 ]\n",
            " [0.24474864 0.7552513 ]\n",
            " [0.3462392  0.6537608 ]\n",
            " [0.32890838 0.6710916 ]\n",
            " [0.48173946 0.5182605 ]\n",
            " [0.26529086 0.73470914]\n",
            " [0.42833173 0.5716683 ]\n",
            " [0.38115573 0.6188442 ]\n",
            " [0.23249331 0.7675067 ]\n",
            " [0.17351851 0.8264815 ]\n",
            " [0.3658209  0.6341791 ]\n",
            " [0.23185618 0.7681438 ]\n",
            " [0.32860342 0.67139655]\n",
            " [0.23215094 0.767849  ]\n",
            " [0.2332121  0.76678795]\n",
            " [0.41846284 0.5815372 ]\n",
            " [0.18961723 0.8103827 ]\n",
            " [0.29509968 0.70490026]\n",
            " [0.48623535 0.5137647 ]\n",
            " [0.22033925 0.7796607 ]\n",
            " [0.16205214 0.83794785]\n",
            " [0.15854801 0.84145194]\n",
            " [0.3742494  0.62575054]\n",
            " [0.27489161 0.7251084 ]\n",
            " [0.22645366 0.77354634]\n",
            " [0.2222695  0.77773046]\n",
            " [0.30118617 0.69881386]\n",
            " [0.8060511  0.19394894]\n",
            " [0.16731338 0.8326866 ]\n",
            " [0.31066525 0.68933475]\n",
            " [0.19587284 0.80412716]\n",
            " [0.24302877 0.7569712 ]\n",
            " [0.125694   0.874306  ]\n",
            " [0.468685   0.53131497]\n",
            " [0.36577442 0.63422555]\n",
            " [0.25305998 0.74694   ]\n",
            " [0.2358605  0.7641395 ]\n",
            " [0.23933104 0.760669  ]\n",
            " [0.24917576 0.7508243 ]\n",
            " [0.13150194 0.868498  ]\n",
            " [0.34014463 0.65985537]\n",
            " [0.27595967 0.7240403 ]\n",
            " [0.12475362 0.87524635]\n",
            " [0.29804862 0.7019514 ]\n",
            " [0.2026433  0.7973566 ]\n",
            " [0.47325948 0.52674055]\n",
            " [0.33271274 0.66728723]\n",
            " [0.28664106 0.713359  ]\n",
            " [0.23768887 0.7623111 ]\n",
            " [0.37701005 0.62298995]\n",
            " [0.47352737 0.5264727 ]\n",
            " [0.45653543 0.5434646 ]\n",
            " [0.20489843 0.7951016 ]\n",
            " [0.3738661  0.62613386]\n",
            " [0.4869552  0.5130448 ]\n",
            " [0.13438185 0.86561817]\n",
            " [0.482728   0.517272  ]\n",
            " [0.14910686 0.8508931 ]\n",
            " [0.5663043  0.43369564]\n",
            " [0.43364272 0.56635725]\n",
            " [0.4859748  0.5140252 ]\n",
            " [0.54513097 0.454869  ]\n",
            " [0.5197751  0.48022485]\n",
            " [0.25816116 0.7418388 ]\n",
            " [0.42213908 0.5778609 ]\n",
            " [0.3945235  0.6054765 ]\n",
            " [0.41080204 0.58919793]\n",
            " [0.13526486 0.8647351 ]\n",
            " [0.32612568 0.67387426]\n",
            " [0.42987463 0.57012534]\n",
            " [0.36721486 0.6327851 ]\n",
            " [0.3321499  0.6678501 ]\n",
            " [0.57240623 0.4275937 ]\n",
            " [0.12979746 0.87020254]\n",
            " [0.26867476 0.73132527]\n",
            " [0.43453088 0.5654691 ]\n",
            " [0.2623645  0.73763543]\n",
            " [0.30257815 0.69742185]\n",
            " [0.23866582 0.7613341 ]\n",
            " [0.13660349 0.86339647]\n",
            " [0.40966067 0.5903393 ]\n",
            " [0.26042414 0.73957586]\n",
            " [0.39661175 0.6033883 ]\n",
            " [0.11514512 0.88485485]\n",
            " [0.1630862  0.8369138 ]\n",
            " [0.36523792 0.63476205]\n",
            " [0.47918853 0.52081144]\n",
            " [0.21750371 0.78249633]\n",
            " [0.21407062 0.7859294 ]\n",
            " [0.13374826 0.86625177]\n",
            " [0.23828258 0.76171744]\n",
            " [0.3832164  0.6167836 ]\n",
            " [0.25057298 0.749427  ]] (14.499 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.51828825.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            " Total features in pool2 layer should be 8*8*64 and it is found to be : 4096\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-11-23T18:08:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-11-23-18:08:31\n",
            "INFO:tensorflow:Saving dict for global step 2500: accuracy = 0.5, global_step = 2500, loss = 0.7970974\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt-2500\n",
            "{'accuracy': 0.5, 'loss': 0.7970974, 'global_step': 2500}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wfiyb37o1-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}