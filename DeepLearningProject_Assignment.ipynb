{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "DeepLearningProject - Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelVinay91/Deeplearning/blob/master/DeepLearningProject_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Y_O4pmo1-e",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Project: Pet Classifier using CNN\n",
        "\n",
        "Prepration\n",
        "- Extract the ipynb file and the data in the same folder\n",
        "\n",
        "Data Set\n",
        "- A production grade program as 10,000 training images\n",
        "- This is a small program with 20 images of cats and 20 images of dogs. \n",
        "- The evaluation set has 10 images of cats and 10 images of dogs\n",
        "\n",
        "Runs\n",
        "- The student is expected to run the 100-300 training step\n",
        "- A production grade code would have about 20k-50k training steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4P0c0Mvo1-h",
        "colab_type": "text"
      },
      "source": [
        "### Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwnUmt6Eo1-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "47bd90b6-5aba-4649-8762-ad88a00e0a16"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_FV1pYQo1-l",
        "colab_type": "text"
      },
      "source": [
        "### Set hyper parameters\n",
        "- Run the program with three num_steps : 100,200,300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFX4zO9qo1-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "img_size = 32\n",
        "num_channels = 3\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "img_shape = (img_size, img_size)\n",
        "trainpath='/content/drive/My Drive/DL_CNN_Project_DataSet/data/train'\n",
        "testpath='/content/drive/My Drive/DL_CNN_Project_DataSet/data/test'\n",
        "labels = {'cats': 0, 'dogs': 1}\n",
        "fc_size=32 #size of the output of final FC layer\n",
        "num_steps=300 #Try 100, 200, 300. number of steps that training data should be looped. Usually 20K\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glPLRBg1o1-o",
        "colab_type": "text"
      },
      "source": [
        "### Read the image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU8m1060o1-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "2e08bee7-c88b-4dbd-ae10-a89eeaa54ae1"
      },
      "source": [
        "def read_images_classes(basepath,imgSize=img_size):\n",
        "    image_stack = []\n",
        "    label_stack = []\n",
        "\n",
        "    for counter, l in enumerate(labels):\n",
        "        path = os.path.join(basepath, l,'*g')\n",
        "        for img in glob.glob(path):\n",
        "            one_hot_vector =np.zeros(len(labels),dtype=np.int16)\n",
        "            one_hot_vector[counter]=1\n",
        "            image = cv2.imread(img)\n",
        "            im_resize = cv2.resize(image,img_shape, interpolation=cv2.INTER_CUBIC)\n",
        "            image_stack.append(im_resize)\n",
        "            label_stack.append(labels[l])            \n",
        "    return np.array(image_stack), np.array(label_stack)\n",
        "\n",
        "X_train, y_train=read_images_classes(trainpath)\n",
        "X_test, y_test=read_images_classes(testpath)\n",
        "\n",
        "#test a sample image\n",
        "print('length of train image set',len(X_train))\n",
        "print('X_data shape:', X_train.shape)\n",
        "print('y_data shape:', y_train.shape)\n",
        "\n",
        "fig1 = plt.figure() \n",
        "ax1 = fig1.add_subplot(2,2,1) \n",
        "img = cv2.resize(X_train[0],(64,64), interpolation=cv2.INTER_CUBIC)\n",
        "ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(y_train[0])\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of train image set 40\n",
            "X_data shape: (40, 32, 32, 3)\n",
            "y_data shape: (40,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIQAAACSCAYAAACEy2IhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZSXSc3Vo1-t",
        "colab_type": "text"
      },
      "source": [
        "### Assignment: Define the tensorflow model\n",
        "\n",
        "The model should have the following layers\n",
        "- input later\n",
        "- conv layer 1 with 32 filters of kernel  size[5,5],\n",
        "- pooling layer 1 with pool size[2,2] and stride 2\n",
        "- conv layer 2 with 64 filters of kernel  size[5,5],\n",
        "- pooling layer 2 with pool size[2,2] and stride 2\n",
        "- dense layer whose output size is fixed in the hyper parameter: fc_size=32\n",
        "- drop out layer with droput probability 0.4\n",
        "- predict the class by doing a softmax on the output of the dropout layers\n",
        "\n",
        "Training\n",
        "- For training define the loss function and minimize it\n",
        "- For evaluation calculate the accuracy\n",
        "\n",
        "Reading Material\n",
        "- For ideas look at tensorflow layers tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aZBDDF2o1-t",
        "colab_type": "text"
      },
      "source": [
        "### The cnn_model_fn has to be defined here by the student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGE1vxnNo1-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model_fn(features, labels, mode):\n",
        "    # Input Layer\n",
        "    input_layer = tf.reshape(features[\"x\"], [-1, img_size, img_size, num_channels])\n",
        "\n",
        "    # Convolutional Layer #1\n",
        "    conv1 = tf.layers.conv2d(\n",
        "        inputs=input_layer,\n",
        "        filters=32,\n",
        "        kernel_size=[5, 5],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    # Pooling Layer #1\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    # Convolutional Layer #2 and Pooling Layer #2\n",
        "    conv2 = tf.layers.conv2d(\n",
        "        inputs=pool1,\n",
        "        filters=64,\n",
        "        kernel_size=[5, 5],\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu)\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    # Flattening pooling layer before connecting fully connected layer\n",
        "    layer_shape = pool2.get_shape()\n",
        "    num_features = layer_shape[1:4].num_elements();\n",
        "    print( \" Total features in pool2 layer should be 8*8*64 and it is found to be :\" ,num_features)\n",
        "    \n",
        "    # Dense Layer\n",
        "    pool2_flat = tf.reshape(pool2, [-1, num_features])\n",
        "    dense = tf.layers.dense(inputs=pool2_flat, units=fc_size, activation=tf.nn.relu)\n",
        "    dropout = tf.layers.dropout(\n",
        "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    # Logits Layer\n",
        "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
        "\n",
        "    predictions = {\n",
        "        # Generate predictions (for PREDICT and EVAL mode)\n",
        "        \"classes\": tf.argmax(input=logits, axis=1),\n",
        "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
        "        # `logging_hook`.\n",
        "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
        "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
        "\n",
        "    # Configure the Training Op (for TRAIN mode)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "    # Add evaluation metrics (for EVAL mode)\n",
        "    eval_metric_ops = {\n",
        "        \"accuracy\": tf.metrics.accuracy(\n",
        "            labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmrvznRFo1-x",
        "colab_type": "text"
      },
      "source": [
        "### Run the tensorflow model\n",
        "\n",
        "This section will use the model defined by the student and run the training and evaluation step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQD-qZWBo1-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e688db88-f139-41e7-a011-04c5675f7395"
      },
      "source": [
        "#X_train = np.array((X_train/255.0),dtype=np.float16)\n",
        "#X_test = np.array((X_test/255.0), dtype=np.float16)\n",
        "X_train = np.array((X_train/255.0),dtype=np.float32)\n",
        "X_test = np.array((X_test/255.0), dtype=np.float32)\n",
        "\n",
        "pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model\")\n",
        "#pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n",
        "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
        "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_train}, y=y_train, batch_size=10,\n",
        "                                                      num_epochs=None, shuffle=True)\n",
        "pets_classifier.train(input_fn=train_input_fn, steps=num_steps, hooks=[logging_hook])\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_test}, y=y_test, num_epochs=1,shuffle=False)\n",
        "eval_results = pets_classifier.evaluate(input_fn=eval_input_fn)\n",
        "print(eval_results)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f787bf2e6d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            " Total features in pool2 layer should be 8*8*64 and it is found to be : 4096\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt-700\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 700 into /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:probabilities = [[0.44957212 0.5504279 ]\n",
            " [0.47073665 0.5292633 ]\n",
            " [0.4457598  0.5542402 ]\n",
            " [0.42416772 0.57583225]\n",
            " [0.4894363  0.51056373]\n",
            " [0.3738795  0.62612045]\n",
            " [0.55062026 0.4493798 ]\n",
            " [0.50393486 0.49606508]\n",
            " [0.42884445 0.5711556 ]\n",
            " [0.37976226 0.62023777]]\n",
            "INFO:tensorflow:loss = 0.6401407, step = 701\n",
            "INFO:tensorflow:probabilities = [[0.5060454  0.49395457]\n",
            " [0.6138407  0.38615933]\n",
            " [0.5320431  0.46795687]\n",
            " [0.3470152  0.65298474]\n",
            " [0.40656653 0.59343344]\n",
            " [0.4170361  0.5829639 ]\n",
            " [0.4347861  0.5652139 ]\n",
            " [0.5087099  0.4912901 ]\n",
            " [0.5038775  0.49612254]\n",
            " [0.5301926  0.46980733]] (1.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.3285\n",
            "INFO:tensorflow:probabilities = [[0.54418606 0.455814  ]\n",
            " [0.5087096  0.49129036]\n",
            " [0.51633507 0.48366496]\n",
            " [0.39281067 0.6071893 ]\n",
            " [0.43755725 0.5624428 ]\n",
            " [0.6114873  0.3885127 ]\n",
            " [0.603584   0.39641595]\n",
            " [0.5849519  0.41504812]\n",
            " [0.5862987  0.41370127]\n",
            " [0.4374478  0.5625522 ]] (1.836 sec)\n",
            "INFO:tensorflow:loss = 0.6190814, step = 801 (3.798 sec)\n",
            "INFO:tensorflow:probabilities = [[0.56101406 0.4389859 ]\n",
            " [0.5060348  0.4939652 ]\n",
            " [0.50982726 0.49017277]\n",
            " [0.6689816  0.33101842]\n",
            " [0.80079687 0.19920321]\n",
            " [0.5883009  0.41169915]\n",
            " [0.34455696 0.6554431 ]\n",
            " [0.48316124 0.5168388 ]\n",
            " [0.42114785 0.5788522 ]\n",
            " [0.63699883 0.36300114]] (1.824 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.528\n",
            "INFO:tensorflow:probabilities = [[0.28676596 0.71323407]\n",
            " [0.13145067 0.8685494 ]\n",
            " [0.3088509  0.6911491 ]\n",
            " [0.42269614 0.5773039 ]\n",
            " [0.3225281  0.6774719 ]\n",
            " [0.5720208  0.4279792 ]\n",
            " [0.47111654 0.52888346]\n",
            " [0.15904433 0.8409556 ]\n",
            " [0.16058874 0.83941126]\n",
            " [0.32106626 0.67893374]] (1.814 sec)\n",
            "INFO:tensorflow:loss = 0.46392792, step = 901 (3.643 sec)\n",
            "INFO:tensorflow:probabilities = [[0.88966954 0.1103304 ]\n",
            " [0.8810745  0.11892551]\n",
            " [0.8112549  0.18874504]\n",
            " [0.89355415 0.10644582]\n",
            " [0.67313796 0.32686204]\n",
            " [0.82847023 0.1715298 ]\n",
            " [0.8414706  0.15852934]\n",
            " [0.6830778  0.31692225]\n",
            " [0.64841455 0.35158542]\n",
            " [0.2908654  0.7091346 ]] (1.831 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.23441446.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            " Total features in pool2 layer should be 8*8*64 and it is found to be : 4096\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-11-23T17:06:24Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-11-23-17:06:25\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.45, global_step = 1000, loss = 0.69134676\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /content/drive/My Drive/DL_CNN_Project_DataSet/pets_convnet_model/model.ckpt-1000\n",
            "{'accuracy': 0.45, 'loss': 0.69134676, 'global_step': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wfiyb37o1-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}